{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec6f642",
   "metadata": {
    "id": "2ec6f642"
   },
   "source": [
    "# Proyecto práctico: árbol de decisión y random forest con scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "490e87d5",
   "metadata": {
    "id": "490e87d5"
   },
   "outputs": [],
   "source": [
    "#Importamos las librerias principales\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qfCfVtTSKkp1",
   "metadata": {
    "id": "qfCfVtTSKkp1"
   },
   "source": [
    "Utilizaremos el **Car Evaluation Data Set** de Kaggle: https://www.kaggle.com/datasets/elikplim/car-evaluation-data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "myIOgyJeLRmS",
   "metadata": {
    "id": "myIOgyJeLRmS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique count</th>\n",
       "      <th>unique values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>buying price</th>\n",
       "      <td>4</td>\n",
       "      <td>[vhigh, high, med, low]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maintinance price</th>\n",
       "      <td>4</td>\n",
       "      <td>[vhigh, high, med, low]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number of doors</th>\n",
       "      <td>4</td>\n",
       "      <td>[2, 3, 4, 5more]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persons capacity</th>\n",
       "      <td>3</td>\n",
       "      <td>[2, 4, more]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>luggage boot</th>\n",
       "      <td>3</td>\n",
       "      <td>[small, med, big]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>safty stimated</th>\n",
       "      <td>3</td>\n",
       "      <td>[med, high, low]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>4</td>\n",
       "      <td>[unacc, acc, vgood, good]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   unique count              unique values\n",
       "buying price                  4    [vhigh, high, med, low]\n",
       "maintinance price             4    [vhigh, high, med, low]\n",
       "number of doors               4           [2, 3, 4, 5more]\n",
       "persons capacity              3               [2, 4, more]\n",
       "luggage boot                  3          [small, med, big]\n",
       "safty stimated                3           [med, high, low]\n",
       "target                        4  [unacc, acc, vgood, good]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "path=\"/home/dan/PLATZI/data/Fundamentals/randomforestsalgorithms/data/external\"\n",
    "colum_names=[\"buying price\",\"maintinance price\",\"number of doors\",\"persons capacity\",\"luggage boot\",\"safty stimated\",\"target\"]\n",
    "\n",
    "#Cargamos dataset a utilizar\n",
    "df=pd.read_csv(path+\"/car_evaluation.csv\")\n",
    "df.columns=colum_names\n",
    "categorical= df.select_dtypes(include=['object']).columns\n",
    "uniqueValsSumary={\n",
    "    col:{'unique count':df[col].nunique(),'unique values':df[col].unique().tolist()}\n",
    "    for col in categorical\n",
    "    \n",
    "}\n",
    "uniqueValsSumary=pd.DataFrame.from_dict(uniqueValsSumary,orient='index')\n",
    "uniqueValsSumary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd08d6ec",
   "metadata": {},
   "source": [
    "it apear all columns are categorical  by default even the ones that use numbers, a proper encoding will have to be in order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7991db",
   "metadata": {
    "id": "3d7991db"
   },
   "source": [
    "## Análisis exploratorio de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47f28d83",
   "metadata": {
    "id": "47f28d83"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying price</th>\n",
       "      <th>maintinance price</th>\n",
       "      <th>number of doors</th>\n",
       "      <th>persons capacity</th>\n",
       "      <th>luggage boot</th>\n",
       "      <th>safty stimated</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying price maintinance price number of doors persons capacity  \\\n",
       "0        vhigh             vhigh               2                2   \n",
       "1        vhigh             vhigh               2                2   \n",
       "2        vhigh             vhigh               2                2   \n",
       "\n",
       "  luggage boot safty stimated target  \n",
       "0        small            med  unacc  \n",
       "1        small           high  unacc  \n",
       "2          med            low  unacc  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualizacion del dataframe\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65495bf7",
   "metadata": {
    "id": "65495bf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the data frame\n",
      "12089\n",
      "================================================================\n",
      "frecuenzy of each category\n",
      "Value counts for: buying price\n",
      "buying price\n",
      "high     432\n",
      "med      432\n",
      "low      432\n",
      "vhigh    431\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value counts for: maintinance price\n",
      "maintinance price\n",
      "high     432\n",
      "med      432\n",
      "low      432\n",
      "vhigh    431\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value counts for: number of doors\n",
      "number of doors\n",
      "3        432\n",
      "4        432\n",
      "5more    432\n",
      "2        431\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value counts for: persons capacity\n",
      "persons capacity\n",
      "4       576\n",
      "more    576\n",
      "2       575\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value counts for: luggage boot\n",
      "luggage boot\n",
      "med      576\n",
      "big      576\n",
      "small    575\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value counts for: safty stimated\n",
      "safty stimated\n",
      "med     576\n",
      "high    576\n",
      "low     575\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value counts for: target\n",
      "target\n",
      "unacc    1209\n",
      "acc       384\n",
      "good       69\n",
      "vgood      65\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Analizamos el shape del objeto\n",
    "print(\"size of the data frame\")\n",
    "print(df.size)\n",
    "print(\"=\"*64)\n",
    "print(\"frecuenzy of each category\")\n",
    "for col in df.columns:\n",
    "    print(f\"Value counts for: {col}\")\n",
    "    print(df[col].value_counts())\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d40faf",
   "metadata": {},
   "source": [
    "the target  classes are unbalance ofcourse here the numbers\n",
    "- unacc    1209\n",
    "- acc       384\n",
    "- good       69\n",
    "- vgood      65\n",
    "all the other columns are more less at equilibrium so the distributions are uniform, there are no missing values ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d74bd0f3",
   "metadata": {
    "id": "d74bd0f3"
   },
   "outputs": [],
   "source": [
    "#we will separate and train a class tree not having on acount the umbalance\n",
    "X=df.drop([\"target\"],axis=1)\n",
    "Y=df[\"target\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3, random_state=37)\n",
    "verification={\"xtrain\":X_train.shape,\"xtest\":X_test.shape,\"ytrain\":Y_train.shape,\"Ytest\":Y_test.shape}\n",
    "import json\n",
    "# esto esta echo para terminal no para el text output de los jupyter\n",
    "#pp(json.dumps(verification,indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7196b0f0",
   "metadata": {
    "id": "7196b0f0"
   },
   "outputs": [],
   "source": [
    "#encoding using third party encoder because:\n",
    "    #random forest dont bennefit from higth sparse matrix\n",
    "    # one hot doesnt suport higth cardinality well\n",
    "    # the encodings are target inform\n",
    "    # good integration with sklearn pipelines\n",
    "    #what is target leakage in this context?\n",
    "#import category_encoders as ce and is not functionning because outdated\n",
    "from sklearn.preprocessing import OrdinalEncoder \n",
    "colum_names=[\"buying price\",\"maintinance price\",\"number of doors\",\"persons capacity\",\"luggage boot\",\"safty stimated\"]\n",
    "encoder=OrdinalEncoder()\n",
    "X_train=encoder.fit_transform(X_train)\n",
    "X_test=encoder.transform(X_test)\n",
    "from sklearn.tree  import DecisionTreeClassifier\n",
    "tree=DecisionTreeClassifier(max_depth=2,random_state=37)\n",
    "tree.fit(X_train,Y_train)\n",
    "train_predictions=tree.predict(X_train)\n",
    "predictions=tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc065546",
   "metadata": {
    "id": "cc065546"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:0.77, and test accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "#to evaluate a model any model its important to be clear on \n",
    "#whats a confussion matrix\n",
    "#sensitibity or recall: all true how many picked; acuracy : the ones clasified how many true\n",
    "#pressicion: from  of all that where say true  how many hhere positive true\n",
    "# espesificity : proportions of true negatives\n",
    "#F1 score integrates presicion and sensibility \n",
    "from sklearn.metrics import accuracy_score\n",
    "#cheking for over fitting\n",
    "train_accuracy=accuracy_score(Y_train,train_predictions)\n",
    "accuracy=accuracy_score(Y_test,predictions)\n",
    "print(f\"train accuracy:{np.round(train_accuracy,2)}, and test accuracy: {np.round(accuracy,2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f217761",
   "metadata": {},
   "source": [
    "as you see the accuracy in both scenarios is simillar so  there is no over or under fitting, never the lees the accuracy should be  o between 90 and 80 porcent to have a good model., lets traina model with a more balance data set to see what happens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa95713",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train.dtype,X_train.dtype)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a72692dc",
   "metadata": {
    "id": "a72692dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'high'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_5603/2911901075.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      9\u001b[39m X_balanced, X_test, Y_balanced,Y_test=train_test_split(X,Y,test_size=\u001b[32m0.3\u001b[39m, random_state=\u001b[32m37\u001b[39m,stratify= Y)\n\u001b[32m     10\u001b[39m balancedTree=DecisionTreeClassifier(max_depth=\u001b[32m2\u001b[39m,random_state=\u001b[32m37\u001b[39m,class_weight=\u001b[33m'balanced'\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m#balancedTree.fit(X_resampled,y_resampled)\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m#resampled_predictions=balancedTree.predict(X_resampled)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m balancedTree.fit(X_balanced,Y_balanced)\n\u001b[32m     14\u001b[39m train_predictions=balancedTree.predict(X_train)\n\u001b[32m     15\u001b[39m predictions= balancedTree.predict(X_test)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m#accuracy mesures\u001b[39;00m\n",
      "\u001b[32m~/anaconda3/envs/desicionTrees/lib/python3.11/site-packages/sklearn/tree/_classes.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input)\u001b[39m\n\u001b[32m    965\u001b[39m         self : DecisionTreeClassifier\n\u001b[32m    966\u001b[39m             Fitted estimator.\n\u001b[32m    967\u001b[39m         \"\"\"\n\u001b[32m    968\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m         super().fit(\n\u001b[32m    970\u001b[39m             X,\n\u001b[32m    971\u001b[39m             y,\n\u001b[32m    972\u001b[39m             sample_weight=sample_weight,\n",
      "\u001b[32m~/anaconda3/envs/desicionTrees/lib/python3.11/site-packages/sklearn/tree/_classes.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input)\u001b[39m\n\u001b[32m    168\u001b[39m             \u001b[38;5;66;03m# We can't pass multi_output=True because that would allow y to be\u001b[39;00m\n\u001b[32m    169\u001b[39m             \u001b[38;5;66;03m# csr.\u001b[39;00m\n\u001b[32m    170\u001b[39m             check_X_params = dict(dtype=DTYPE, accept_sparse=\u001b[33m\"csc\"\u001b[39m)\n\u001b[32m    171\u001b[39m             check_y_params = dict(ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m             X, y = self._validate_data(\n\u001b[32m    173\u001b[39m                 X, y, validate_separately=(check_X_params, check_y_params)\n\u001b[32m    174\u001b[39m             )\n\u001b[32m    175\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "\u001b[32m~/anaconda3/envs/desicionTrees/lib/python3.11/site-packages/sklearn/base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, reset, validate_separately, **check_params)\u001b[39m\n\u001b[32m    587\u001b[39m                 \u001b[38;5;66;03m# :(\u001b[39;00m\n\u001b[32m    588\u001b[39m                 check_X_params, check_y_params = validate_separately\n\u001b[32m    589\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"estimator\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m check_X_params:\n\u001b[32m    590\u001b[39m                     check_X_params = {**default_check_params, **check_X_params}\n\u001b[32m--> \u001b[39m\u001b[32m591\u001b[39m                 X = check_array(X, input_name=\u001b[33m\"X\"\u001b[39m, **check_X_params)\n\u001b[32m    592\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"estimator\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m check_y_params:\n\u001b[32m    593\u001b[39m                     check_y_params = {**default_check_params, **check_y_params}\n\u001b[32m    594\u001b[39m                 y = check_array(y, input_name=\u001b[33m\"y\"\u001b[39m, **check_y_params)\n",
      "\u001b[32m~/anaconda3/envs/desicionTrees/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m    853\u001b[39m                         )\n\u001b[32m    854\u001b[39m                     array = array.astype(dtype, casting=\u001b[33m\"unsafe\"\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    855\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    856\u001b[39m                     array = np.asarray(array, order=order, dtype=dtype)\n\u001b[32m--> \u001b[39m\u001b[32m857\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m    858\u001b[39m                 raise ValueError(\n\u001b[32m    859\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m    860\u001b[39m                 ) from complex_warning\n",
      "\u001b[32m~/anaconda3/envs/desicionTrees/lib/python3.11/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2164\u001b[39m             )\n\u001b[32m   2165\u001b[39m         values = self._values\n\u001b[32m   2166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2167\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2168\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2171\u001b[39m \n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'high'"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=37)\n",
    "Y_train.astype('category')\n",
    "print(Y_train.dtype)\n",
    "# ros dont work easyly with no numeric features.\n",
    "#X_resampled, y_resampled = ros.fit_resample(X_train, Y_train)\n",
    "#stratified sampling  ensures the train test split respects the original dataset ratio\n",
    "X_balanced, X_test, Y_balanced,Y_test=train_test_split(X,Y,test_size=0.3, random_state=37,stratify= Y)\n",
    "balancedTree=DecisionTreeClassifier(max_depth=2,random_state=37,class_weight='balanced')\n",
    "#balancedTree.fit(X_resampled,y_resampled)\n",
    "#resampled_predictions=balancedTree.predict(X_resampled)\n",
    "balancedTree.fit(X_balanced,Y_balanced)\n",
    "train_predictions=balancedTree.predict(X_train)\n",
    "predictions= balancedTree.predict(X_test)\n",
    "#accuracy mesures\n",
    "#resampled_accuracy=accuracy_score(y_resampled,resampled_predictions)\n",
    "train_accuracy=accuracy_score(Y_train,train_predictions)\n",
    "accuracy=accuracy_score(Y_test,predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00530ece",
   "metadata": {
    "id": "00530ece"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_deprecate_Xt_in_inverse_transform' from 'sklearn.utils.deprecation' (/home/dan/anaconda3/envs/desicionTrees/lib/python3.11/site-packages/sklearn/utils/deprecation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimblearn\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mscikit-learn:\u001b[39m\u001b[33m\"\u001b[39m, sklearn.__version__)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mimbalanced-learn:\u001b[39m\u001b[33m\"\u001b[39m, imblearn.__version__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/desicionTrees/lib/python3.11/site-packages/imblearn/__init__.py:52\u001b[39m\n\u001b[32m     48\u001b[39m     sys.stderr.write(\u001b[33m\"\u001b[39m\u001b[33mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[32m     50\u001b[39m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     53\u001b[39m         combine,\n\u001b[32m     54\u001b[39m         ensemble,\n\u001b[32m     55\u001b[39m         exceptions,\n\u001b[32m     56\u001b[39m         metrics,\n\u001b[32m     57\u001b[39m         over_sampling,\n\u001b[32m     58\u001b[39m         pipeline,\n\u001b[32m     59\u001b[39m         tensorflow,\n\u001b[32m     60\u001b[39m         under_sampling,\n\u001b[32m     61\u001b[39m         utils,\n\u001b[32m     62\u001b[39m     )\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_version\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/desicionTrees/lib/python3.11/site-packages/imblearn/combine/__init__.py:5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_smote_enn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_smote_tomek\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[32m      8\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mSMOTEENN\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSMOTETomek\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/desicionTrees/lib/python3.11/site-packages/imblearn/combine/_smote_enn.py:12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mover_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mover_sampling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/desicionTrees/lib/python3.11/site-packages/imblearn/base.py:15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_metadata_requests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m METHODS\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmulticlass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_sampling_strategy, check_target_type\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sklearn_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _fit_context, get_tags, validate_data\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArraysTransformer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/desicionTrees/lib/python3.11/site-packages/imblearn/utils/__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThe :mod:`imblearn.utils` module includes various utilities.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_docstring\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Substitution\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     check_neighbors_object,\n\u001b[32m      8\u001b[39m     check_sampling_strategy,\n\u001b[32m      9\u001b[39m     check_target_type,\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m __all__ = [\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcheck_neighbors_object\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcheck_sampling_strategy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcheck_target_type\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mSubstitution\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/desicionTrees/lib/python3.11/site-packages/imblearn/utils/_validation.py:20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmulticlass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m type_of_target\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _num_samples\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sklearn_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _is_pandas_df, check_array\n\u001b[32m     22\u001b[39m SAMPLING_KIND = (\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mover-sampling\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     24\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33munder-sampling\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbypass\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     28\u001b[39m )\n\u001b[32m     29\u001b[39m TARGET_KIND = (\u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmultilabel-indicator\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/desicionTrees/lib/python3.11/site-packages/imblearn/utils/_sklearn_compat.py:815\u001b[39m\n\u001b[32m    811\u001b[39m \u001b[38;5;129m@dataclass\u001b[39m(**_dataclass_args())\n\u001b[32m    812\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTags\u001b[39;00m(Tags):\n\u001b[32m    813\u001b[39m     sampler_tags: SamplerTags | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m815\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_test_common\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minstance_generator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    816\u001b[39m     _construct_instances,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m    817\u001b[39m )\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mestimator_checks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    819\u001b[39m     check_estimator,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m    820\u001b[39m     parametrize_with_checks,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m    821\u001b[39m )\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmulticlass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m type_of_target  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/desicionTrees/lib/python3.11/site-packages/sklearn/utils/_test_common/instance_generator.py:13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone, config_context\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcalibration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CalibratedClassifierCV\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     14\u001b[39m     HDBSCAN,\n\u001b[32m     15\u001b[39m     AffinityPropagation,\n\u001b[32m     16\u001b[39m     AgglomerativeClustering,\n\u001b[32m     17\u001b[39m     Birch,\n\u001b[32m     18\u001b[39m     BisectingKMeans,\n\u001b[32m     19\u001b[39m     FeatureAgglomeration,\n\u001b[32m     20\u001b[39m     KMeans,\n\u001b[32m     21\u001b[39m     MeanShift,\n\u001b[32m     22\u001b[39m     MiniBatchKMeans,\n\u001b[32m     23\u001b[39m     SpectralBiclustering,\n\u001b[32m     24\u001b[39m     SpectralClustering,\n\u001b[32m     25\u001b[39m     SpectralCoclustering,\n\u001b[32m     26\u001b[39m )\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompose\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcovariance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GraphicalLasso, GraphicalLassoCV\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/desicionTrees/lib/python3.11/site-packages/sklearn/cluster/__init__.py:7\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Authors: The scikit-learn developers\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: BSD-3-Clause\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_affinity_propagation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AffinityPropagation, affinity_propagation\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_agglomerative\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      8\u001b[39m     AgglomerativeClustering,\n\u001b[32m      9\u001b[39m     FeatureAgglomeration,\n\u001b[32m     10\u001b[39m     linkage_tree,\n\u001b[32m     11\u001b[39m     ward_tree,\n\u001b[32m     12\u001b[39m )\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_bicluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SpectralBiclustering, SpectralCoclustering\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_birch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Birch\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/desicionTrees/lib/python3.11/site-packages/sklearn/cluster/_agglomerative.py:44\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# mypy error: Module 'sklearn.cluster' has no attribute '_hierarchical_fast'\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _hierarchical_fast \u001b[38;5;28;01mas\u001b[39;00m _hierarchical  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_feature_agglomeration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AgglomerationTransform\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# For non fully-connected graphs\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fix_connectivity\u001b[39m(X, connectivity, affinity):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/desicionTrees/lib/python3.11/site-packages/sklearn/cluster/_feature_agglomeration.py:15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TransformerMixin\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m metadata_routing\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdeprecation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _deprecate_Xt_in_inverse_transform\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_is_fitted, validate_data\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Mixin class for feature agglomeration.\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name '_deprecate_Xt_in_inverse_transform' from 'sklearn.utils.deprecation' (/home/dan/anaconda3/envs/desicionTrees/lib/python3.11/site-packages/sklearn/utils/deprecation.py)"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import imblearn\n",
    "print(\"scikit-learn:\", sklearn.__version__)\n",
    "print(\"imbalanced-learn:\", imblearn.__version__)\n",
    "#Verificamos valores missings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86s30LYeLbu9",
   "metadata": {
    "id": "86s30LYeLbu9"
   },
   "source": [
    "## Procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f409b9",
   "metadata": {
    "id": "06f409b9"
   },
   "outputs": [],
   "source": [
    "#Separamos en X e y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dae560",
   "metadata": {
    "id": "66dae560"
   },
   "outputs": [],
   "source": [
    "#Importamos las librerias necesarias para la creacion del modelo\n",
    "\n",
    "\n",
    "#30% para test y 70% para train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8a9218",
   "metadata": {
    "id": "ad8a9218"
   },
   "outputs": [],
   "source": [
    "#Veamos que obtuvimos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08ca811",
   "metadata": {
    "id": "b08ca811"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d533850",
   "metadata": {
    "id": "9d533850"
   },
   "outputs": [],
   "source": [
    "#Veamos que tenemos. Por ejemplo, en X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc96bbeb",
   "metadata": {
    "id": "cc96bbeb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15fcff4d",
   "metadata": {
    "id": "15fcff4d"
   },
   "source": [
    "## Entrenamiento de modelo de clasificación con árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2912bb66",
   "metadata": {
    "id": "2912bb66"
   },
   "outputs": [],
   "source": [
    "#Importante: todos nuestros tipos de datos son object, realizamos una transformacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21959865",
   "metadata": {
    "id": "21959865"
   },
   "outputs": [],
   "source": [
    "#Verificamos la transformacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295219ed",
   "metadata": {
    "id": "295219ed"
   },
   "outputs": [],
   "source": [
    "#Importar árbol de decisión\n",
    "\n",
    "#Creacion del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b095479",
   "metadata": {
    "id": "3b095479"
   },
   "outputs": [],
   "source": [
    "#Entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136e0d36",
   "metadata": {
    "id": "136e0d36"
   },
   "outputs": [],
   "source": [
    "#Calculo de las predicciones en Train y Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82235b72",
   "metadata": {
    "id": "82235b72"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4EQEEyNhMzv_",
   "metadata": {
    "id": "4EQEEyNhMzv_"
   },
   "source": [
    "## Evaluación de modelo de clasificación con árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78168ad8",
   "metadata": {
    "id": "78168ad8"
   },
   "outputs": [],
   "source": [
    "#Calculo de metricas \n",
    "\n",
    "\n",
    "#Calculo el accuracy en Train\n",
    "\n",
    "\n",
    "#Calculo el accuracy en Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f20870",
   "metadata": {
    "id": "56f20870"
   },
   "outputs": [],
   "source": [
    "#Verificamos el feature importances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a7b543",
   "metadata": {
    "id": "c6a7b543"
   },
   "source": [
    "## Entrenamiento de modelo de clasificación con random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c065cb",
   "metadata": {
    "id": "c5c065cb"
   },
   "outputs": [],
   "source": [
    "#Importar random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d19673",
   "metadata": {
    "id": "d8d19673"
   },
   "outputs": [],
   "source": [
    "#Calculo de las predicciones en Train y Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299KcCgiPgqY",
   "metadata": {
    "id": "299KcCgiPgqY"
   },
   "source": [
    "## Evaluación de modelo de clasificación con random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41abea2d",
   "metadata": {
    "id": "41abea2d"
   },
   "outputs": [],
   "source": [
    "#Calculo de metricas \n",
    "\n",
    "\n",
    "#Calculo el accuracy en Train\n",
    "\n",
    "\n",
    "#Calculo el accuracy en Test\n",
    "\n",
    "\n",
    "#Importante: podriamos reducir el numero de estimadores para disminuir el sobreajuste del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcde499",
   "metadata": {
    "id": "9bcde499"
   },
   "outputs": [],
   "source": [
    "# Visualizacion de las feature importantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fc2e26",
   "metadata": {
    "id": "d1fc2e26"
   },
   "outputs": [],
   "source": [
    "#Grafico de barras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f81084",
   "metadata": {
    "id": "03f81084"
   },
   "outputs": [],
   "source": [
    "# Matriz de confusion del RF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be61c64b",
   "metadata": {
    "id": "be61c64b"
   },
   "outputs": [],
   "source": [
    "#RF\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "desicionTrees",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
