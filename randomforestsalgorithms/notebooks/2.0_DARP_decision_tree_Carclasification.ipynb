{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec6f642",
   "metadata": {
    "id": "2ec6f642"
   },
   "source": [
    "# Proyecto práctico: árbol de decisión y random forest con scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "490e87d5",
   "metadata": {
    "id": "490e87d5"
   },
   "outputs": [],
   "source": [
    "#Importamos las librerias principales\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qfCfVtTSKkp1",
   "metadata": {
    "id": "qfCfVtTSKkp1"
   },
   "source": [
    "Utilizaremos el **Car Evaluation Data Set** de Kaggle: https://www.kaggle.com/datasets/elikplim/car-evaluation-data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "myIOgyJeLRmS",
   "metadata": {
    "id": "myIOgyJeLRmS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique count</th>\n",
       "      <th>unique values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>buying price</th>\n",
       "      <td>4</td>\n",
       "      <td>[vhigh, high, med, low]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maintinance price</th>\n",
       "      <td>4</td>\n",
       "      <td>[vhigh, high, med, low]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number of doors</th>\n",
       "      <td>4</td>\n",
       "      <td>[2, 3, 4, 5more]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persons capacity</th>\n",
       "      <td>3</td>\n",
       "      <td>[2, 4, more]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>luggage boot</th>\n",
       "      <td>3</td>\n",
       "      <td>[small, med, big]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>safty stimated</th>\n",
       "      <td>3</td>\n",
       "      <td>[med, high, low]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>4</td>\n",
       "      <td>[unacc, acc, vgood, good]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   unique count              unique values\n",
       "buying price                  4    [vhigh, high, med, low]\n",
       "maintinance price             4    [vhigh, high, med, low]\n",
       "number of doors               4           [2, 3, 4, 5more]\n",
       "persons capacity              3               [2, 4, more]\n",
       "luggage boot                  3          [small, med, big]\n",
       "safty stimated                3           [med, high, low]\n",
       "target                        4  [unacc, acc, vgood, good]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "path=\"/home/dan/PLATZI/data/Fundamentals/randomforestsalgorithms/data/external\"\n",
    "colum_names=[\"buying price\",\"maintinance price\",\"number of doors\",\"persons capacity\",\"luggage boot\",\"safty stimated\",\"target\"]\n",
    "\n",
    "#Cargamos dataset a utilizar\n",
    "df=pd.read_csv(path+\"/car_evaluation.csv\")\n",
    "df.columns=colum_names\n",
    "categorical= df.select_dtypes(include=['object']).columns\n",
    "uniqueValsSumary={\n",
    "    col:{'unique count':df[col].nunique(),'unique values':df[col].unique().tolist()}\n",
    "    for col in categorical\n",
    "    \n",
    "}\n",
    "uniqueValsSumary=pd.DataFrame.from_dict(uniqueValsSumary,orient='index')\n",
    "uniqueValsSumary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd08d6ec",
   "metadata": {},
   "source": [
    "it apear all columns are categorical  by default even the ones that use numbers, a proper encoding will have to be in order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7991db",
   "metadata": {
    "id": "3d7991db"
   },
   "source": [
    "## Análisis exploratorio de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47f28d83",
   "metadata": {
    "id": "47f28d83"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying price</th>\n",
       "      <th>maintinance price</th>\n",
       "      <th>number of doors</th>\n",
       "      <th>persons capacity</th>\n",
       "      <th>luggage boot</th>\n",
       "      <th>safty stimated</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying price maintinance price number of doors persons capacity  \\\n",
       "0        vhigh             vhigh               2                2   \n",
       "1        vhigh             vhigh               2                2   \n",
       "2        vhigh             vhigh               2                2   \n",
       "\n",
       "  luggage boot safty stimated target  \n",
       "0        small            med  unacc  \n",
       "1        small           high  unacc  \n",
       "2          med            low  unacc  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualizacion del dataframe\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65495bf7",
   "metadata": {
    "id": "65495bf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the data frame\n",
      "12089\n",
      "================================================================\n",
      "frecuenzy of each category\n",
      "Value counts for: buying price\n",
      "buying price\n",
      "high     432\n",
      "med      432\n",
      "low      432\n",
      "vhigh    431\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value counts for: maintinance price\n",
      "maintinance price\n",
      "high     432\n",
      "med      432\n",
      "low      432\n",
      "vhigh    431\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value counts for: number of doors\n",
      "number of doors\n",
      "3        432\n",
      "4        432\n",
      "5more    432\n",
      "2        431\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value counts for: persons capacity\n",
      "persons capacity\n",
      "4       576\n",
      "more    576\n",
      "2       575\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value counts for: luggage boot\n",
      "luggage boot\n",
      "med      576\n",
      "big      576\n",
      "small    575\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value counts for: safty stimated\n",
      "safty stimated\n",
      "med     576\n",
      "high    576\n",
      "low     575\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value counts for: target\n",
      "target\n",
      "unacc    1209\n",
      "acc       384\n",
      "good       69\n",
      "vgood      65\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Analizamos el shape del objeto\n",
    "print(\"size of the data frame\")\n",
    "print(df.size)\n",
    "print(\"=\"*64)\n",
    "print(\"frecuenzy of each category\")\n",
    "for col in df.columns:\n",
    "    print(f\"Value counts for: {col}\")\n",
    "    print(df[col].value_counts())\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d40faf",
   "metadata": {},
   "source": [
    "the target  classes are unbalance ofcourse here the numbers\n",
    "- unacc    1209\n",
    "- acc       384\n",
    "- good       69\n",
    "- vgood      65\n",
    "all the other columns are more less at equilibrium so the distributions are uniform, there are no missing values ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74bd0f3",
   "metadata": {
    "id": "d74bd0f3"
   },
   "outputs": [],
   "source": [
    "#we will separate and train a class tree not having on acount the umbalance\n",
    "X=df.drop([\"target\"],axis=1)\n",
    "Y=df[\"target\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3, random_state=37,stratify=Y)\n",
    "# the stratify astribute is necesary because the  encoder for labels does not know what to doo \n",
    "# when  in the test set you ask it to transforma a category never seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7196b0f0",
   "metadata": {
    "id": "7196b0f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.60357498 0.         0.39642502]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=OrdinalEncoder()\n",
    "labeler=LabelEncoder()\n",
    "X_train=encoder.fit_transform(X_train)\n",
    "X_test=encoder.transform(X_test)\n",
    "Y_train=labeler.fit_transform(Y_train)\n",
    "Y_test=labeler.transform(Y_test)\n",
    "from sklearn.tree  import DecisionTreeClassifier\n",
    "tree=DecisionTreeClassifier(max_depth=2,random_state=37)\n",
    "tree.fit(X_train,Y_train)\n",
    "train_predictions=tree.predict(X_train)\n",
    "predictions=tree.predict(X_test)\n",
    "print(tree.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc065546",
   "metadata": {
    "id": "cc065546"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:0.76, and test accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#cheking for over fitting\n",
    "train_accuracy=accuracy_score(Y_train,train_predictions)\n",
    "accuracy=accuracy_score(Y_test,predictions)\n",
    "print(f\"train accuracy:{np.round(train_accuracy,2)}, and test accuracy: {np.round(accuracy,2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f217761",
   "metadata": {},
   "source": [
    "as you see the accuracy in both scenarios is simillar so  there is no over or under fitting, never the lees the accuracy should be  o between 90 and 80 porcent to have a good model., lets traina model with a more balance data set to see what happens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a72692dc",
   "metadata": {
    "id": "a72692dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:0.76, and test accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=37)\n",
    "# ros dont work easyly with no numeric features.\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, Y_train)\n",
    "#stratified sampling  ensures the train test split respects the original dataset ratio\n",
    "balancedTree=DecisionTreeClassifier(max_depth=2,random_state=37)\n",
    "balancedTree.fit(X_train,Y_train)\n",
    "train_predictions=balancedTree.predict(X_train)\n",
    "predictions= balancedTree.predict(X_test)\n",
    "#accuracy mesures\n",
    "train_accuracy=accuracy_score(Y_train,train_predictions)\n",
    "accuracy=accuracy_score(Y_test,predictions)\n",
    "print(f\"train accuracy:{np.round(train_accuracy,2)}, and test accuracy: {np.round(accuracy,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d9ba58",
   "metadata": {},
   "source": [
    "### This is a surprise\n",
    "\n",
    "When the hyperparameter `class_weight` is used in `'balanced'` mode, what happens under the hood is that an error misclassifying a minority class gets a higher penalty. This can lead to **overfitting** for the minority class unless parameters like `max_depth`, `min_samples_leaf`, or `min_samples_split` are properly tuned.\n",
    "\n",
    "Also, plain accuracy may not be the best metric because of this overfitting. A model might perform very well on the majority class and poorly on the minority class, yet still show high accuracy. This can be misleading — especially if, in production, the class imbalance does not exist.\n",
    "\n",
    "In other cases, manual balancing is necessary using techniques like **SMOTE**, **random oversampling**, or **undersampling**.\n",
    "\n",
    "\n",
    "#### balanced accuracy score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00530ece",
   "metadata": {
    "id": "00530ece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:0.36, and test accuracy: 0.37\n"
     ]
    }
   ],
   "source": [
    "#balanced accuracy makes a  weigthed avrage of the recall\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "train_accuracy=balanced_accuracy_score(Y_train,train_predictions)\n",
    "accuracy=balanced_accuracy_score(Y_test,predictions)\n",
    "print(f\"train accuracy:{np.round(train_accuracy,2)}, and test accuracy: {np.round(accuracy,2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54928b3f",
   "metadata": {},
   "source": [
    "So, our decision tree is actually worse than we thought. Let's try to manually balance the dataset and create another tree to see what happens.\n",
    "\n",
    "Since our minority class has around **50 data points**, and decision trees tend to work well with small datasets, I feel inclined to use **undersampling**. However, the final decision will depend on **IBM's `imblearn` compatibility**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1adc9ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before undersampling target\n",
      "unacc    1209\n",
      "acc       384\n",
      "good       69\n",
      "vgood      65\n",
      "Name: count, dtype: int64\n",
      "after undersampling target\n",
      "acc      65\n",
      "good     65\n",
      "unacc    65\n",
      "vgood    65\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "print(\"before undersampling\",Y.value_counts())\n",
    "undersampler=RandomUnderSampler(random_state=37)\n",
    "x,y=undersampler.fit_resample(X,Y)\n",
    "print(\"after undersampling\",y.value_counts())\n",
    "encoder=OrdinalEncoder()\n",
    "labeler=LabelEncoder()\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=37,stratify=y)\n",
    "x_train=encoder.fit_transform(x_train)\n",
    "x_test=encoder.transform(x_test)\n",
    "y_train=labeler.fit_transform(y_train)\n",
    "y_test=labeler.transform(y_test)\n",
    "tree=DecisionTreeClassifier(max_depth=2,random_state=37)\n",
    "tree=tree.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f76af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy 0.5274725274725275, test accuracy0.5384615384615384\n"
     ]
    }
   ],
   "source": [
    "train_predictions=tree.predict(x_train)\n",
    "predictions=tree.predict(x_test)\n",
    "accuracy_train=accuracy_score(y_train,train_predictions)\n",
    "accuracy_test=accuracy_score(y_test,predictions)\n",
    "print(f\"train accuracy {accuracy_train}, test accuracy{accuracy_test}\")\n",
    "#when no maxdepth use  the results are 1 and 0.88 a very likely overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86s30LYeLbu9",
   "metadata": {
    "id": "86s30LYeLbu9"
   },
   "source": [
    "no better than a coin toss , meyby with  more samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06f409b9",
   "metadata": {
    "id": "06f409b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before undersampling target\n",
      "unacc    1209\n",
      "acc       384\n",
      "good       69\n",
      "vgood      65\n",
      "Name: count, dtype: int64\n",
      "after undersampling target\n",
      "unacc    1209\n",
      "acc      1209\n",
      "vgood    1209\n",
      "good     1209\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "print(\"before undersampling\",Y.value_counts())\n",
    "oversampler=RandomOverSampler(random_state=37)\n",
    "x,y=oversampler.fit_resample(X,Y)\n",
    "print(\"after undersampling\",y.value_counts())\n",
    "encoder=OrdinalEncoder()\n",
    "labeler=LabelEncoder()\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=37,stratify=y)\n",
    "x_train=encoder.fit_transform(x_train)\n",
    "x_test=encoder.transform(x_test)\n",
    "y_train=labeler.fit_transform(y_train)\n",
    "y_test=labeler.transform(y_test)\n",
    "tree=DecisionTreeClassifier(max_depth=2,random_state=37)\n",
    "tree=tree.fit(x_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66dae560",
   "metadata": {
    "id": "66dae560"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy 0.507533234859675, test accuracy0.5134390075809786\n"
     ]
    }
   ],
   "source": [
    "train_predictions=tree.predict(x_train)\n",
    "predictions=tree.predict(x_test)\n",
    "accuracy_train=accuracy_score(y_train,train_predictions)\n",
    "accuracy_test=accuracy_score(y_test,predictions)\n",
    "print(f\"train accuracy {accuracy_train}, test accuracy{accuracy_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8a9218",
   "metadata": {
    "id": "ad8a9218"
   },
   "source": [
    "what happens here  having on acount that when the data set wasa imbalanced, in proportions was like having just 2 clases, when its  balanced we do have 4 classes it makes me think, decicion trees are very good in binary clasification, but not in multy class. lets see the feature importance in the   balanced tree vs the umbalance tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b08ca811",
   "metadata": {
    "id": "b08ca811"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.56517124 0.         0.43482876]\n"
     ]
    }
   ],
   "source": [
    "features=tree.feature_importances_\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d533850",
   "metadata": {
    "id": "9d533850"
   },
   "outputs": [],
   "source": [
    "#Veamos que tenemos. Por ejemplo, en X_train\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc96bbeb",
   "metadata": {
    "id": "cc96bbeb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15fcff4d",
   "metadata": {
    "id": "15fcff4d"
   },
   "source": [
    "## Entrenamiento de modelo de clasificación con árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2912bb66",
   "metadata": {
    "id": "2912bb66"
   },
   "outputs": [],
   "source": [
    "#Importante: todos nuestros tipos de datos son object, realizamos una transformacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21959865",
   "metadata": {
    "id": "21959865"
   },
   "outputs": [],
   "source": [
    "#Verificamos la transformacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295219ed",
   "metadata": {
    "id": "295219ed"
   },
   "outputs": [],
   "source": [
    "#Importar árbol de decisión\n",
    "\n",
    "#Creacion del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b095479",
   "metadata": {
    "id": "3b095479"
   },
   "outputs": [],
   "source": [
    "#Entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136e0d36",
   "metadata": {
    "id": "136e0d36"
   },
   "outputs": [],
   "source": [
    "#Calculo de las predicciones en Train y Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82235b72",
   "metadata": {
    "id": "82235b72"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4EQEEyNhMzv_",
   "metadata": {
    "id": "4EQEEyNhMzv_"
   },
   "source": [
    "## Evaluación de modelo de clasificación con árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78168ad8",
   "metadata": {
    "id": "78168ad8"
   },
   "outputs": [],
   "source": [
    "#Calculo de metricas \n",
    "\n",
    "\n",
    "#Calculo el accuracy en Train\n",
    "\n",
    "\n",
    "#Calculo el accuracy en Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f20870",
   "metadata": {
    "id": "56f20870"
   },
   "outputs": [],
   "source": [
    "#Verificamos el feature importances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a7b543",
   "metadata": {
    "id": "c6a7b543"
   },
   "source": [
    "## Entrenamiento de modelo de clasificación con random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c065cb",
   "metadata": {
    "id": "c5c065cb"
   },
   "outputs": [],
   "source": [
    "#Importar random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d19673",
   "metadata": {
    "id": "d8d19673"
   },
   "outputs": [],
   "source": [
    "#Calculo de las predicciones en Train y Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299KcCgiPgqY",
   "metadata": {
    "id": "299KcCgiPgqY"
   },
   "source": [
    "## Evaluación de modelo de clasificación con random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41abea2d",
   "metadata": {
    "id": "41abea2d"
   },
   "outputs": [],
   "source": [
    "#Calculo de metricas \n",
    "\n",
    "\n",
    "#Calculo el accuracy en Train\n",
    "\n",
    "\n",
    "#Calculo el accuracy en Test\n",
    "\n",
    "\n",
    "#Importante: podriamos reducir el numero de estimadores para disminuir el sobreajuste del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcde499",
   "metadata": {
    "id": "9bcde499"
   },
   "outputs": [],
   "source": [
    "# Visualizacion de las feature importantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fc2e26",
   "metadata": {
    "id": "d1fc2e26"
   },
   "outputs": [],
   "source": [
    "#Grafico de barras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f81084",
   "metadata": {
    "id": "03f81084"
   },
   "outputs": [],
   "source": [
    "# Matriz de confusion del RF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be61c64b",
   "metadata": {
    "id": "be61c64b"
   },
   "outputs": [],
   "source": [
    "#RF\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "desicionTrees",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
